"""
Stage 2: é«˜ç²¾åº¦æ–‡çŒ®æ¤œç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

Stage 1ã®åŒ»å­¦ç”¨èªæ­£è¦åŒ–çµæœã‚’æ´»ç”¨ã—ã¦ã€PubMedæ¤œç´¢ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚
OpenAI APIã«ã‚ˆã‚‹æ¤œç´¢ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã€‚
"""

import json
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from openai import OpenAI

from src.config import settings
from src.core.medical_normalizer_v2 import MedicalTermNormalizer, NormalizedClaim
from src.utils.pubmed import PubMedSearcher, PubMedArticle

logger = logging.getLogger(__name__)


@dataclass
class LiteratureSearchResult:
    """æ–‡çŒ®æ¤œç´¢çµæœãƒ‡ãƒ¼ã‚¿"""
    original_claim: str
    normalized_claim: NormalizedClaim
    search_queries: List[str]
    articles: List[PubMedArticle]
    search_summary: str
    confidence: float
    api_used: str


@dataclass
class ArticleRelevance:
    """è«–æ–‡é–¢é€£åº¦è©•ä¾¡"""
    article: PubMedArticle
    relevance_score: float
    relevance_reasoning: str
    evidence_strength: str  # "strong", "moderate", "weak", "insufficient"
    supports_claim: Optional[bool]  # True=æ”¯æŒ, False=åå¯¾, None=ä¸æ˜


class LiteratureSearcher:
    """é«˜ç²¾åº¦æ–‡çŒ®æ¤œç´¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, preferred_api: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            preferred_api: ä½¿ç”¨ã™ã‚‹API ("openai", "gemini", "deepseek", "fallback")
        """
        self.preferred_api = preferred_api or settings.literature_search_api
        self.normalizer = MedicalTermNormalizer()
        self.pubmed_searcher = PubMedSearcher()
        
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.openai_client = None
        if settings.openai_api_key:
            try:
                self.openai_client = OpenAI(api_key=settings.openai_api_key)
                logger.info("âœ… LiteratureSearcher: OpenAI APIåˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.warning(f"âŒ LiteratureSearcher: OpenAI APIåˆæœŸåŒ–å¤±æ•—: {e}")
    
    def search_literature(self, claim_text: str, max_articles: int = 10) -> LiteratureSearchResult:
        """
        åŒ…æ‹¬çš„ãªæ–‡çŒ®æ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            claim_text: æ¤œç´¢å¯¾è±¡ã®ä¸»å¼µ
            max_articles: å–å¾—ã™ã‚‹æœ€å¤§è«–æ–‡æ•°
            
        Returns:
            LiteratureSearchResult: æ¤œç´¢çµæœ
        """
        logger.info(f"ğŸ” æ–‡çŒ®æ¤œç´¢é–‹å§‹: {claim_text[:50]}...")
        
        # Step 1: åŒ»å­¦ç”¨èªæ­£è¦åŒ–
        normalized = self.normalizer.normalize_claim(claim_text)
        logger.info(f"ğŸ“‹ æ­£è¦åŒ–å®Œäº†: {normalized.search_query}")
        
        # Step 2: æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆãƒ»æœ€é©åŒ–
        search_queries = self._generate_optimized_queries(normalized)
        logger.info(f"ğŸ”§ æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ: {len(search_queries)}å€‹")
        
        # Step 3: PubMedæ¤œç´¢å®Ÿè¡Œ
        all_articles = []
        for query in search_queries:
            articles = self.pubmed_searcher.search_articles(query, max_articles // len(search_queries))
            all_articles.extend(articles)
        
        # é‡è¤‡é™¤å»
        unique_articles = self._remove_duplicates(all_articles)
        logger.info(f"ğŸ“š æ¤œç´¢çµæœ: {len(unique_articles)}ä»¶ã®è«–æ–‡")
        
        # Step 4: é–¢é€£åº¦è©•ä¾¡ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if self.openai_client and len(unique_articles) > 0:
            filtered_articles = self._evaluate_article_relevance(normalized, unique_articles[:max_articles])
        else:
            filtered_articles = unique_articles[:max_articles]
        
        # Step 5: æ¤œç´¢ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        search_summary = self._generate_search_summary(normalized, filtered_articles)
        
        confidence = self._calculate_search_confidence(normalized, filtered_articles)
        
        return LiteratureSearchResult(
            original_claim=claim_text,
            normalized_claim=normalized,
            search_queries=search_queries,
            articles=filtered_articles,
            search_summary=search_summary,
            confidence=confidence,
            api_used=normalized.api_used
        )
    
    def _generate_optimized_queries(self, normalized: NormalizedClaim) -> List[str]:
        """æ­£è¦åŒ–çµæœã‹ã‚‰æœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ"""
        
        if not self.openai_client:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªç”Ÿæˆ
            return self._generate_fallback_queries(normalized)
        
        try:
            prompt = f"""
ä»¥ä¸‹ã®æ­£è¦åŒ–ã•ã‚ŒãŸåŒ»å­¦ä¸»å¼µã«ã¤ã„ã¦ã€PubMedæ¤œç´¢ç”¨ã®åŠ¹æœçš„ãªã‚¯ã‚¨ãƒªã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

æ­£è¦åŒ–çµæœ:
- åŒ»å­¦ç”¨èª: {', '.join(normalized.medical_terms)}
- åŸºæœ¬ã‚¯ã‚¨ãƒª: {normalized.search_query}
- åŒ»å­¦åˆ†é‡: {normalized.medical_field}
- ä»‹å…¥: {normalized.intervention}
- çµæœ: {normalized.outcome}
- å¯¾è±¡é›†å›£: {normalized.population}

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰å¤šè§’çš„ãªã‚¯ã‚¨ãƒªã‚’ä½œæˆ:
1. ç›´æ¥çš„ãªä»‹å…¥-çµæœé–¢ä¿‚ã®ç ”ç©¶
2. ç³»çµ±çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒ¡ã‚¿è§£æ
3. æœ€æ–°ã®è‡¨åºŠç ”ç©¶

é‡è¦ãªè¦æ±‚:
- MeSHç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨
- ç ”ç©¶ã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å«ã‚ã‚‹
- è‹±èªã®æ­£ç¢ºãªåŒ»å­¦ç”¨èªã‚’ä½¿ç”¨
- å„ã‚¯ã‚¨ãƒªã¯ç•°ãªã‚‹æ¤œç´¢æˆ¦ç•¥ã‚’æ¡ç”¨

JSONé…åˆ—å½¢å¼ã§å‡ºåŠ›:
["query1", "query2", "query3"]
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "PubMedæ¤œç´¢ã®å°‚é–€å®¶ã¨ã—ã¦ã€åŠ¹æœçš„ãªæ¤œç´¢æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=500
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0]
            elif "[" in content and "]" in content:
                start = content.find("[")
                end = content.rfind("]") + 1
                json_str = content[start:end]
            else:
                json_str = content
            
            queries = json.loads(json_str)
            
            if isinstance(queries, list) and len(queries) > 0:
                logger.info(f"âœ… OpenAI APIã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªæœ€é©åŒ–æˆåŠŸ: {len(queries)}å€‹")
                return queries
            else:
                raise ValueError("Invalid query format")
                
        except Exception as e:
            logger.warning(f"âŒ OpenAI ã‚¯ã‚¨ãƒªæœ€é©åŒ–å¤±æ•—: {e}")
            return self._generate_fallback_queries(normalized)
    
    def _generate_fallback_queries(self, normalized: NormalizedClaim) -> List[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒªç”Ÿæˆ"""
        queries = []
        
        # åŸºæœ¬ã‚¯ã‚¨ãƒª
        base_query = normalized.search_query
        if base_query:
            queries.append(base_query + " AND humans[MeSH Terms] AND english[Language]")
        
        # ä»‹å…¥+çµæœã®ã‚¯ã‚¨ãƒª
        if normalized.intervention and normalized.outcome:
            intervention_outcome = f"{normalized.intervention} AND {normalized.outcome}"
            queries.append(intervention_outcome + " AND (randomized controlled trial[Publication Type] OR meta-analysis[Publication Type])")
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡å°‚ç”¨ã‚¯ã‚¨ãƒª
        if len(normalized.medical_terms) > 0:
            review_query = " ".join(normalized.medical_terms[:3])
            queries.append(review_query + " AND (systematic review[Publication Type] OR meta-analysis[Publication Type])")
        
        return queries[:3] if queries else [normalized.search_query or "medical research"]
    
    def _remove_duplicates(self, articles: List[PubMedArticle]) -> List[PubMedArticle]:
        """é‡è¤‡è«–æ–‡ã‚’é™¤å»"""
        seen_pmids = set()
        unique_articles = []
        
        for article in articles:
            if article.pmid not in seen_pmids:
                seen_pmids.add(article.pmid)
                unique_articles.append(article)
        
        return unique_articles
    
    def _evaluate_article_relevance(self, normalized: NormalizedClaim, articles: List[PubMedArticle]) -> List[PubMedArticle]:
        """OpenAI APIã‚’ä½¿ç”¨ã—ã¦è«–æ–‡ã®é–¢é€£åº¦ã‚’è©•ä¾¡"""
        
        if not self.openai_client or not articles:
            return articles
        
        evaluated_articles = []
        
        for article in articles[:10]:  # æœ€åˆã®10ä»¶ã‚’è©•ä¾¡
            try:
                relevance = self._evaluate_single_article(normalized, article)
                if relevance.relevance_score >= 0.6:  # é–¢é€£åº¦60%ä»¥ä¸Šã®ã¿ä¿æŒ
                    evaluated_articles.append(article)
                    logger.debug(f"âœ… è«–æ–‡æ¡ç”¨: {article.title[:50]}... (é–¢é€£åº¦: {relevance.relevance_score:.2f})")
                else:
                    logger.debug(f"âŒ è«–æ–‡é™¤å¤–: {article.title[:50]}... (é–¢é€£åº¦: {relevance.relevance_score:.2f})")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è«–æ–‡è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                evaluated_articles.append(article)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¿æŒ
        
        return evaluated_articles
    
    def _evaluate_single_article(self, normalized: NormalizedClaim, article: PubMedArticle) -> ArticleRelevance:
        """å˜ä¸€è«–æ–‡ã®é–¢é€£åº¦ã‚’è©•ä¾¡"""
        
        prompt = f"""
ä»¥ä¸‹ã®åŒ»å­¦è«–æ–‡ãŒã€æŒ‡å®šã•ã‚ŒãŸä¸»å¼µã«ã©ã®ç¨‹åº¦é–¢é€£ã—ã¦ã„ã‚‹ã‹è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ä¸»å¼µã®æ­£è¦åŒ–çµæœ:
- åŒ»å­¦ç”¨èª: {', '.join(normalized.medical_terms)}
- æ¤œç´¢ã‚¯ã‚¨ãƒª: {normalized.search_query}
- åŒ»å­¦åˆ†é‡: {normalized.medical_field}
- ä»‹å…¥: {normalized.intervention}
- çµæœ: {normalized.outcome}

è«–æ–‡æƒ…å ±:
- ã‚¿ã‚¤ãƒˆãƒ«: {article.title}
- ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {article.abstract[:800]}
- ç ”ç©¶ã‚¿ã‚¤ãƒ—: {article.study_type}
- ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«: {article.journal}

ä»¥ä¸‹ã®å½¢å¼ã§JSONè©•ä¾¡ã‚’å‡ºåŠ›:
{{
    "relevance_score": 0.0ã‹ã‚‰1.0ã®æ•°å€¤,
    "relevance_reasoning": "é–¢é€£åº¦ã®ç†ç”±ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
    "evidence_strength": "strong/moderate/weak/insufficient",
    "supports_claim": true/false/null
}}

è©•ä¾¡åŸºæº–:
- 1.0: ä¸»å¼µã«ç›´æ¥é–¢é€£ã—ã€é«˜å“è³ªãªç ”ç©¶
- 0.8: ä¸»å¼µã«é–¢é€£ã—ã€ä¿¡é ¼ã§ãã‚‹ç ”ç©¶
- 0.6: éƒ¨åˆ†çš„ã«é–¢é€£ã€å‚è€ƒã«ãªã‚‹
- 0.4: é–“æ¥çš„ã«é–¢é€£
- 0.2: ã‚ãšã‹ã«é–¢é€£
- 0.0: é–¢é€£ãªã—
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "åŒ»å­¦æ–‡çŒ®ã®é–¢é€£åº¦è©•ä¾¡ã®å°‚é–€å®¶ã¨ã—ã¦ã€å®¢è¦³çš„ã§å³æ ¼ãªè©•ä¾¡ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=300
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSONæŠ½å‡º
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0]
            elif "{" in content and "}" in content:
                start = content.find("{")
                end = content.rfind("}") + 1
                json_str = content[start:end]
            else:
                json_str = content
            
            result = json.loads(json_str)
            
            return ArticleRelevance(
                article=article,
                relevance_score=result.get("relevance_score", 0.5),
                relevance_reasoning=result.get("relevance_reasoning", "è©•ä¾¡ä¸å¯"),
                evidence_strength=result.get("evidence_strength", "insufficient"),
                supports_claim=result.get("supports_claim")
            )
            
        except Exception as e:
            logger.warning(f"è«–æ–‡é–¢é€£åº¦è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return ArticleRelevance(
                article=article,
                relevance_score=0.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                relevance_reasoning="è‡ªå‹•è©•ä¾¡å¤±æ•—",
                evidence_strength="insufficient",
                supports_claim=None
            )
    
    def _generate_search_summary(self, normalized: NormalizedClaim, articles: List[PubMedArticle]) -> str:
        """æ¤œç´¢çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        
        if not articles:
            return f"ã€Œ{normalized.search_query}ã€ã«é–¢ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ
        study_types = {}
        for article in articles:
            study_type = article.study_type or "other"
            study_types[study_type] = study_types.get(study_type, 0) + 1
        
        # æ–°ã—ã„ç ”ç©¶ã®å‰²åˆ
        recent_count = 0
        if articles[0].publication_date:
            from datetime import datetime
            current_year = datetime.now().year
            for article in articles:
                if article.publication_date and (current_year - article.publication_date.year) <= 5:
                    recent_count += 1
        
        study_type_summary = ", ".join([f"{k}: {v}ä»¶" for k, v in study_types.items()])
        
        summary = f"""
æ¤œç´¢ã‚¯ã‚¨ãƒªã€Œ{normalized.search_query}ã€ã§{len(articles)}ä»¶ã®é–¢é€£è«–æ–‡ã‚’ç™ºè¦‹ã€‚
ç ”ç©¶ã‚¿ã‚¤ãƒ—: {study_type_summary}ã€‚
éå»5å¹´ä»¥å†…ã®ç ”ç©¶: {recent_count}ä»¶ã€‚
"""
        
        return summary.strip()
    
    def _calculate_search_confidence(self, normalized: NormalizedClaim, articles: List[PubMedArticle]) -> float:
        """æ¤œç´¢ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
        confidence = 0.0
        
        # æ­£è¦åŒ–ã®ä¿¡é ¼åº¦
        confidence += normalized.confidence * 0.3
        
        # è«–æ–‡æ•°ã«ã‚ˆã‚‹è©•ä¾¡
        if len(articles) >= 5:
            confidence += 0.3
        elif len(articles) >= 2:
            confidence += 0.2
        elif len(articles) >= 1:
            confidence += 0.1
        
        # ç ”ç©¶ã®è³ªã«ã‚ˆã‚‹è©•ä¾¡
        high_quality_count = 0
        for article in articles:
            if article.study_type in ["meta-analysis", "randomized_controlled_trial"]:
                high_quality_count += 1
        
        if high_quality_count >= 2:
            confidence += 0.3
        elif high_quality_count >= 1:
            confidence += 0.2
        
        # APIä½¿ç”¨ã«ã‚ˆã‚‹ä¿¡é ¼åº¦ãƒœãƒ¼ãƒŠã‚¹
        if normalized.api_used != "fallback":
            confidence += 0.1
        
        return min(confidence, 0.95)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
literature_searcher = LiteratureSearcher()